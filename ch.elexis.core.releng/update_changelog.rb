#!/usr/bin/env ruby

require 'bundler/inline'
puts "It may take some time for bundler/inline to install the dependencies"

gemfile do
  source 'https://rubygems.org'
  gem 'optimist'
  gem 'rugged'
  gem 'oga'
  gem "activesupport", :require => "active_support/all"
  gem 'pry-byebug'
end

require 'pp'
begin
require 'pry'
rescue
end
require 'ostruct'
require 'rugged'
require 'optimist'
require 'oga'
require 'open-uri'
require 'yaml'
require 'csv'
require 'fileutils'
require 'active_support/all'

DATE_FORMAT = '%Y.%m.%d'
AUFRUF = "# Generated by #{File.basename(__FILE__)} #{ARGV} on #{Time.now.strftime(DATE_FORMAT)}".gsub("[", '').gsub("]", '').gsub('"','')
ISSUE_URL = 'https://redmine.medelexis.ch/issues'
CACHE_FILE = File.join(Dir.home, '.cache/redmine_issues.yaml')
IGNORE_ISSUE_STATUS = /Abgewiesen|erledigt|zur*ckgestell/i
PR = 'Pull Request'
PR_MATCH = /\(#[\d]*\)/

@options = Optimist::options do
  version "#{File.basename(__FILE__)} (c) 2107 by Niklaus Giger <niklaus.giger@member.fsf.org>"
  banner <<-EOS
Useage:
  if --from is given, --to must be given, too, e.g. --from=release/3.0.25 --to=release/3.1.0
  Collects all release tag, limits them to the local history, creates statistic for
  each tag and then the Changelog
  The issues fetched from #{ISSUE_URL} are cached
  in #{CACHE_FILE} as loading tickets takes a non negligeable time.
  Issues with a status not matching #{IGNORE_ISSUE_STATUS} are reloaded if
  they were not already update via the Redmine-API today.
  #{version}
EOS

  opt :force_tag,       "Use HEAD and force it as tag_name and use it a to tag", :type => String, :default => nil
  opt :with_tickets,    "Emit also information from Medelexis Redmine (needs API) ",  :default => false
  opt :changelog,       'Name of file to be written', :type => String, :default => 'Changelog'
  opt :from,            'Only a difference from the given tag', :type => String, :default => nil
  opt :to,              'Only a difference to the given tag', :type => String, :default => nil
  opt :mediawiki,       'Create Changelog.mediawiki with a summary grouped by weekyl changes/ticket'
  opt :markdown,        'Create Changelog.markdown with a summary grouped by weekyl changes/ticket'
  opt :by_week,         'Group tickets by week'
end

require 'rugged'
MAX_ID = 999
FORCE_TAG_NUMERIC = (MAX_ID.to_s*4).to_i
Issue = Struct.new(:id, :subject, :fixed_version, :git_version,  :status, :project, :last_api_fetch, :tracker)
CommitInfo = Struct.new(:repo, :ticket, :author_date, :committer_date, :text)
class CommitInfo
  def commit_week
    date = Date.parse(committer_date)
    sprintf('%04d Woche %02d', date.year, date.cweek)
  end
end
@scriptStarted = Time.now
@options[:with_tickets] = true if @options[:mediawiki]
if @options[:with_tickets]
  @csv_file_name = "#{@options[:changelog]}.csv"
end
@options[:to] = @options[:force_tag] if  @options[:force_tag]
@no_ticket_ids = 0
@no_emitted_ids = 0

def tag_name_to_numerical_value(tag_name)
  items = []
  if tag_name.index('.b') # beta_vesion
    # release/3.2.0.beta22 0> [3, 2, 0, 22]
    items = tag_name.split('/').last.split(/\.(beta|b)|\./).collect{|x| x.to_i if /^\d/.match(x) }.compact
  else
    items = tag_name.split('/').last.split('.').collect{|x| x.to_i}
    items.insert(-2, MAX_ID)
  end
  if items.size == 3
    sprintf('%03i%03i%03i%03i', items[0], items[2], 0, 0).to_i
  else
    sprintf('%03i%03i%03i%03i', items[0], items[1], items[2], items[3]).to_i
  end
end

TAG_INFO = Struct.new('TAG_INFO', :tag_name, :numerical, :tag, :commit_id, :parent, :tag_date)
@all_taginfos = []

def get_taginfo_by_name(tag_name)
  @all_taginfos.find{ |taginfo| taginfo.tag_name.eql?(tag_name)}
end

def get_release_tags
  @repo = Rugged::Repository.new(Dir.pwd)
  tags = @repo.tags.find_all{|x| x.name.index('release/')}
  tags_hash = {}
  tags.each do |tag|
    next unless /^release/i.match(tag.name)
    next if /alpha/i.match(tag.name)
    tags_hash[tag.name] = tag.target_id
    @all_taginfos << TAG_INFO.new(tag.name, tag_name_to_numerical_value(tag.name),
                                  tag, tag.target_id, nil,
                                  tag.target.committer[:time].strftime(DATE_FORMAT))
  end
  if @options[:force_tag]
    info =  TAG_INFO.new(@options[:force_tag], FORCE_TAG_NUMERIC, @repo.head, @repo.head.target_id)
    info.commit_id =  @repo.head.target_id
    info.tag_date = (Date.today+1).strftime(DATE_FORMAT)
    @all_taginfos << info
  end
  branch_names = @repo.branches.find_all{ |x| /origin\/\d+\.\d+$/.match(x.name)}.collect{|x| x.name}
  branch_names.each do |name|
    tag_id = `git merge-base master #{name}`.chomp
    short_version = /[\d\.]+$/.match(name)[0]
    tag = @repo.rev_parse(tag_id)
    @all_taginfos <<  TAG_INFO.new(name, tag_name_to_numerical_value(short_version), tag, tag.oid, nil, tag.committer[:time].strftime(DATE_FORMAT))
  end
  tags_hash
rescue => error
  puts error
  puts error.backtrace.join("\n")
end

def find_tags_in_current_branch
  newer_id = @repo.references['HEAD'].target_id
  newer_id = @repo.head.target_id
  walker = Rugged::Walker.new(@repo)
  walker.sorting(Rugged::SORT_TOPO | Rugged::SORT_REVERSE) # optional
  walker.push(newer_id)
  res = walker.collect{|c| c};
  @tag_in_local_branch = []
  res.each do |commit|
    if (info = @all_taginfos.find{|taginfo| taginfo.commit_id == commit.oid})
      @tag_in_local_branch << info
      puts "Adding local tag #{info.tag_name} commit #{info.commit_id}" if $VERBOSE
    end
  end
end

def build_branch_history
  previous = nil
  sorted = @tag_in_local_branch.sort_by { |info| info.numerical}
  puts "Sorted are #{sorted.collect{ |x| x.tag_name}.join(',')}"  if $VERBOSE
  sorted.each_with_index do |current, idx|
    unless previous
      previous = current
      next
    end
    @history = current
    current.parent = previous.clone
    previous = current.clone
  end
end

def get_history(old_id, newer_id, git_version)
  old = @repo.lookup(old_id)
  newer = @repo.lookup(newer_id)
  return get_history(newer_id, old_id, git_version) if old.time > newer.time

  info = OpenStruct.new
  walker = Rugged::Walker.new(@repo)
  # walker.sorting(Rugged::SORT_TOPO || Rugged::SORT_DATE) # optional
  walker.push(newer_id)
  walker.hide(old_id)

  info.commits = []
  info.authors = {}
  walker.each do |commit|
    author = commit.author[:name]
    ticket_id = (m =  /^\[(\d*)\]/.match(commit.message)) && m[1]
    ticket = ticket_id ? read_issue(ticket_id) : Issue.new(ticket_id)
    # Handle cases like Issue 19635 not found
    ticket ||= Issue.new(ticket_id)
    ticket.id ||= ticket_id
    first_commit_line = commit.message.split("\n").first
    m = PR_MATCH.match(first_commit_line)
    if m && ticket_id.nil?
      ticket.id ||= m[0]
      ticket.tracker = PR
      ticket.subject = first_commit_line
      ticket.fixed_version = author
    end
    @no_ticket_ids += 1 unless ticket.fixed_version
    ticket.fixed_version ||= "Keine Zielversion"
    ticket.subject ||= "Keine Titel"
    ticket.git_version = git_version
    unless ticket.tracker
      # puts "Skipping #{commit.message}"
      next
    end
    line = "#{commit.oid} #{commit.author[:time]} #{sprintf('%20s', author)} #{first_commit_line}"
    info.commits  << CommitInfo.new(File.basename(File.dirname(@repo.path)), ticket, commit.author[:time].strftime(DATE_FORMAT), commit.committer[:time].strftime(DATE_FORMAT), line)
    info.authors[author] ||= 0
    info.authors[author] += 1
  end
  info
end

def read_issue(id = 5760)
  @nr_loaded ||= 0
  unless ENV['REDMINE_MEDEXIS_API']
    puts "Environment variable REDMINE_MEDEXIS_API must be specified to read an issue from the Medelexis Redmine"
    raise "Missing REDMINE_MEDEXIS_API variable. Get it from https://redmine.medelexis.ch/my/api_key"
  end
  if (ti = @ticket_cache[id])
    ti.last_api_fetch ||= Date.today
    if IGNORE_ISSUE_STATUS.match(ti.status) || ti.last_api_fetch = Date.today
      puts "Skip reading ticket #{id} with status #{ti.status} dated #{ti.last_api_fetch}" if $VERBOSE
      return ti
    end
  end
  issue = Issue.new
  issue.last_api_fetch = Date.today
  content =  URI.open("#{ISSUE_URL}/#{id}.xml",
      "User-Agent" => "Ruby/#{RUBY_VERSION}",
      "X-Redmine-API-Key" => "#{ENV['REDMINE_MEDEXIS_API']}"
    ).read
  # to debug File.open(Dir.pwd+"/#{id}.xml", 'w+') { |file| file.write content}
  document = Oga.parse_xml( content ) ;
  ['id', 'subject'].each do |field|
    cmd = "issue.#{field} = document.xpath('issue/#{field}').first.text"
    eval(cmd)
  end
  ['project', 'status', 'fixed_version', 'tracker'].each do |field|
    cmd = "value = document.xpath('issue/#{field}').first; issue.#{field} = value ? value.get('name') : nil"
    eval(cmd)
  end
  issue.tracker = "Fehler" unless issue.tracker
  issue.subject = issue.subject[0..79] if issue.subject
  puts "Fetched ticket #{id} #{issue.status}" if $VERBOSE
  @nr_loaded += 1
  $stdout.write "\n (re-)loaded #{@nr_loaded} tickets." if @nr_loaded % 100 == 0
  $stdout.write '.'
  @ticket_cache[id] = issue
  issue
rescue OpenURI::HTTPError => error
  puts "Issue #{id} not found"
  return nil
rescue => error
  puts error
  puts error.backtrace.join("\n")
end

PRETTY_HEADERS =
    { "Feature" => "Neue Features",
      "Fehler" => "Behobene Fehler",
      "Test" => "Für Tests",
      "Unterstützung" => "Unterstützungsarbeiten",
      PR => "Merged pull requests"
      }

def createLink(commitId, useMarkdown, project = 'dummy')
  if PR_MATCH.match(commitId) # https://github.com/elexis/elexis-3-base/pull/217
    commitId = commitId.gsub(/[\(\)#]/, '')
    project = "https://github.com/elexis/#{project}/pull"
  else
    project = 'https://redmine.medelexis.ch/issues'
  end
  link = useMarkdown ?
    "**[#{commitId}](#{project}/#{commitId})**" :
    "'''([#{project}/#{commitId} #{commitId}])'''"
end

def emit_mediawiki_changelog(all_commits, file, useMarkdown)
  outfile = File.open(file, 'w+')
  short_version = /[\d\.]+$/.match(@options[:to])[0]
  l1 = useMarkdown ? "#" : '='
  outfile.puts "#{l1} Changelog für Elexis #{short_version} ab #{@options[:from]} bis #{@options[:to]} #{l1}"
  outfile.puts ""
  outfile.puts AUFRUF.sub('# ','')
  outfile.puts "Die Zahlen in Klammern beziehen sich auf das nicht öffentlich zugängliche Ticket-System der Firma Medelexis AG"
  outfile.puts "   gefolgt von der Version in der das Problem zuerst geflickt, resp. zurückportiert wurde. Leer falls keine Zielversion erfasst"
  outfile.puts ""
  if  @options[:by_week]
    sorted = all_commits.sort{|left, right| left.committer_date <=> right.committer_date}
    by_week = {}
    sorted.reverse.each do |commit|
      next unless commit.ticket && commit.ticket.id
      by_week[commit.commit_week] ||= {}
      by_week[commit.commit_week] [commit.ticket.id] = commit
      by_week[commit.commit_week] [:sunday] = Date.parse(commit.committer_date).sunday
    end
    commits.each do | week, values|
      ids = values.keys.find_all{|x| x.is_a?(String)}.uniq.sort;
      outfile.puts "#{l1}#{l1}  #{values[:sunday].strftime('%Y.%m.%d')}: #{ids.size} gelöste Tickets #{l1}#{l1}"
      outfile.puts ""
      ids.each do |id|
        ti = values[id].ticket
        link = createLink(ti.id, useMarkdown)
        line = "* #{link} #{ti.subject.gsub(/\n|\r\n/, ',').strip}"
        outfile.puts line
      end
      outfile.puts ""
    end
  else
    to_sort = all_commits.find_all{|x| x.ticket&.fixed_version.eql?(short_version) || x.ticket&.git_version.sub(/.*\//,'').eql?(short_version) }
    if to_sort
      to_sort.sort{|left, right| left.committer_date <=> right.committer_date}
      sorted_by_ticket  = to_sort.sort{|left, right| left.ticket.id.to_i <=> right.ticket.id.to_i}
      emitted_ids = []
      chapters = sorted_by_ticket.collect{ |x| x.ticket.tracker.to_s }.sort.uniq # ["Feature", "Fehler", "Test", "Unterstützung"]
      chapters.each do |chapter|
        outfile.puts "\n#{l1}#{l1}#{l1} #{PRETTY_HEADERS[chapter]} #{l1}#{l1}#{l1}\n\n"
        sorted_by_ticket.each do|commit|
          next unless commit.ticket.tracker.eql?(chapter)
          next if emitted_ids.index(commit.ticket.id)
          proprietary = !sorted_by_ticket.find_all{|x| x.ticket.id == commit.ticket.id}.collect{|x| x.repo}.uniq.find{ |x| x.match(/^elexis/)}
          commit_id = commit.ticket.id ? commit.ticket.id : "unkown"
          link = createLink(commit_id, useMarkdown, commit.repo)
          line = "* #{proprietary ? 'Medelexis:' : 'OpenSource'} #{link}" +
              " #{commit.ticket.fixed_version}" +
              " #{commit.ticket.subject.gsub(/\n|\r\n/, ',').strip}"
          outfile.puts line
          emitted_ids << commit.ticket.id
        end
      end
      @no_emitted_ids = emitted_ids.size
    end
  end
  outfile.close
end

def emit_changes(ausgabe, from=nil, to=nil)
  raise "from and to must be given" unless to && from
  from_tag =@all_taginfos.find{|x| x.tag_name == from}
  to_tag =@all_taginfos.find{|x| x.tag_name == to}
  info = get_history(from_tag.commit_id, to_tag.commit_id, to_tag.tag_name)
  header = []
  header << ''
  line = "#{info.commits.size} commits between #{from_tag.tag_name} (#{from_tag.tag_date}) and #{to_tag.tag_name} (#{to_tag.tag_date})"
  header << line
  header << '-' * line.size
  header << '   number changes by authors are'
  info.authors.sort_by{|key, value| value}.reverse.each do |author, nr_commits|
    header << "   #{sprintf("%3i", nr_commits)}: #{author}"
  end
  header << '-' * line.size

  header << ''
  puts header if $VERBOSE
  ausgabe.puts header.join("\n")
  ausgabe.puts info.commits.collect{|info| info.text}.join("\n")
  if @csv_file_name
    unless @csv_file # create header
      @csv_file = CSV.open(@csv_file_name, "wb", :encoding => 'utf-8')
      @csv_file << ['id', 'status', 'fixed_version', 'git_version','author_date', 'committer_date', 'subject', 'project', 'text']
    end
    puts "\nAdding #{sprintf('%-25s', to_tag.tag_name)}" #  to #{@csv_file_name}"
    info.commits.each do |ci|
      next unless ci.ticket && ci.ticket.id.to_i > 0
      ti = ci.ticket
      line = [ti.id, ti.status, ti.fixed_version, ti.git_version, ci.author_date, ci.committer_date,
              ti.subject.gsub(/\n|\r\n/, ',').strip, ti.project, ci.text.gsub(/\n|\r\n/, ' ').strip]
      @csv_file << line
    end
  end
end

def emit_history(filename, from = nil, to = nil)
  walk = @history
  filename += "-#{from.sub(/(release|origin)\//,'')}-#{to.sub(/(origin|release)\//,'')}" if from && to
  File.open(filename, 'w+') do |ausgabe|
    ausgabe.puts AUFRUF
    ausgabe.puts "# similar to git log --date=iso --pretty=format:'%H %ad %an %s' release/3.0.25..release/3.1.0"
    if from && to
      emit_changes(ausgabe, from, to)
    else
      while walk && walk.parent
        unless @tag_in_local_branch.find{|x| x.commit_id == walk.parent.commit_id}
          walk = walk.parent
          next
        end
        emit_changes(ausgabe, walk.parent.tag_name, walk.tag_name)
        walk = walk.parent
      end
    end
  end
end

@ticket_cache = File.exist?(CACHE_FILE) ? YAML.load_file(CACHE_FILE) : {}
@ticket_cache = {} unless @ticket_cache.is_a?(Hash)
@nr_loaded ||= 0
$stdout.sync = true
puts "Loaded #{@ticket_cache.size} entries from #{CACHE_FILE}"
at_exit do
  puts "Saving #{@ticket_cache.size} entries to #{CACHE_FILE}"
  FileUtils.mv(CACHE_FILE, CACHE_FILE+ '.backup', :verbose => true) if File.exist?(CACHE_FILE) && File.size(CACHE_FILE) > 100
  File.open(CACHE_FILE,'w+') do |h|
    h.write @ticket_cache.to_yaml
  end if @nr_loaded.size != @ticket_cache.size
end unless (@options[:mediawiki] || @options[:markdown])
# Order of next calls is necessary!
@history = []
if @options[:mediawiki]  || @options[:markdown]
  @format = @options[:mediawiki] ? "mediawiki" : "markdown"
  raise "from and to must be given" unless @options[:from] && @options[:to]
  git_directories = (Dir.glob('.git') + Dir.glob('*/.git')).collect{|x| File.expand_path(File.dirname(x)) }
  mediawiki_file = File.join(Dir.pwd, "Changelog.#{@format}")
  history_all = []
  git_directories.each do |repo|
    Dir.chdir(repo)
    @all_taginfos = []
    @history = []
    get_release_tags
    from_tag = @all_taginfos.find{|x| x.tag_name ==  @options[:from] }
    if from_tag
      from_id = from_tag.commit_id
    else
      from_tag ||= @repo.branches[@options[:from]]
      from_id = from_tag&.target&.oid
    end
    unless from_tag
      puts "Skipping #{repo} as there is no tag #{@options[:from]}" if $VERBOSE
      @repo.ref_names.find{|x| /origin\/3.5/.match(x)}
      next
    end
    to_tag =@all_taginfos.find{|x| x.tag_name ==  @options[:to]}
    info = get_history(from_id, to_tag.commit_id, to_tag.tag_name)
    history_all +=info.commits
    puts "  #{repo}: found #{info.commits.size} history_all now #{history_all.size}"
  end
  emit_mediawiki_changelog(history_all, mediawiki_file, @format.eql?('markdown'))
  puts "Had #{@no_ticket_ids} commits without a ticket id (e.g. merges, wrong ticket-id )"
  puts "Created #{mediawiki_file} #{File.size(mediawiki_file)} bytes for #{@no_emitted_ids} tickets "
else
  get_release_tags
  if @options[:from] && @options[:to]
    emit_history(@options[:changelog], @options[:from], @options[:to])
  else
    find_tags_in_current_branch
    build_branch_history
    emit_history(@options[:changelog])
  end
  puts "\nCreated #{File.expand_path(@options[:changelog])} " +
      "#{@csv_file_name ? ' and ' +  File.expand_path(@csv_file_name) : ' '} " +
      "for #{@options[:from] ? @options[:from] : 'first commit'} up to #{@options[:to] ? @options[:to] : 'HEAD'}"
  @scriptStopped = Time.now
  @diffSeconds = (@scriptStopped-@scriptStarted).to_i
  puts "#{Time.now}: Script finished after #{sprintf('%i:%02i', @diffSeconds/60, @diffSeconds%60)}. Reloaded #{@nr_loaded} redmine tickets"
end
